# Bio-Voice Commander - Complete Experiment Roadmap

**Date**: 2025-12-10
**Status**: Planning Phase
**Goal**: ç³»çµ±åŒ–æå‡ç³»çµ±æ€§èƒ½ï¼Œçªç ´ç•¶å‰ç“¶é ¸

---

## ğŸ“Š Current System Status

### Performance Metrics (2025-12-10)

| Metric | mfcc_dtw | ensemble | Status |
|--------|----------|----------|--------|
| Overall Accuracy | 94.3% | 94.6% | âœ… Excellent |
| Clean Accuracy | 100% | 100% | âœ… Perfect |
| Noise 10dB | 64% | 71% | âš ï¸ **Bottleneck** |
| Average Latency | 165ms | 220ms | âœ… Good |
| Speed Robustness | 97.2% | 97.2% | âœ… Excellent |
| Pitch Robustness | 97.2% | 97.2% | âœ… Excellent |
| Volume Robustness | 100% | 100% | âœ… Perfect |

### Key Findings
- âœ… **Strengths**: Speed/Pitch/Volume ç©©å¥æ€§æ¥µä½³
- âš ï¸ **Bottleneck**: å™ªéŸ³ 10dB æº–ç¢ºç‡åƒ… 64-71% (ç›®æ¨™ >80%)
- ğŸ› **Template Issues**: é–‹å§‹3.wav, é–‹å§‹4.wav å¤šæ¬¡å¤±æ•—
- ğŸ’¡ **Insight**: mel æ–¹æ³•åœ¨å™ªéŸ³ä¸‹ç©©å®š (79% ä¸å— SNR å½±éŸ¿)

---

## ğŸ—ºï¸ Experiment Roadmap

### Phase 1: Quick Wins (A1) â­ PRIORITY
**Timeline**: Week 1 (1-2 days)
**Goal**: å¿«é€Ÿé©—è­‰ adaptive ensemble æ¦‚å¿µ

### Phase 2: Advanced Features (A2, A3)
**Timeline**: Week 2-3 (1-2 weeks)
**Goal**: æ·±åº¦å„ªåŒ–å™ªéŸ³è™•ç†

### Phase 3: Comprehensive Testing (B1, B2)
**Timeline**: Week 4 (3-5 days)
**Goal**: æ›´åš´æ ¼çš„è©•ä¼°æ¨™æº–

### Phase 4: Fine-tuning (C1, C2)
**Timeline**: Week 5 (2-3 days)
**Goal**: åƒæ•¸ç²¾èª¿ï¼Œè¿½æ±‚æ¥µè‡´

---

# ğŸ“‹ Experiment Details

---

## A1: Noise-Adaptive Ensemble â­ **START HERE**

### Overview
**Type**: Advanced Feature
**Difficulty**: â­â­â˜†â˜†â˜† (Low-Medium)
**Time**: ~50 minutes
**Risk**: Low (å¯éš¨æ™‚å›é€€)

### Problem
- Ensemble åœ¨å®‰éœç’°å¢ƒæµªè²»æ™‚é–“è·‘ 3 å€‹æ–¹æ³•
- Ensemble å„ªå‹¢åƒ…åœ¨å™ªéŸ³ç’°å¢ƒï¼ˆ10dB: +7%ï¼‰
- éœ€è¦æ™ºèƒ½åŒ–ï¼šå®‰éœæ™‚å¿«é€Ÿï¼Œå™ªéŸ³æ™‚ç©©å®š

### Hypothesis
> æ ¹æ“š SNR å‹•æ…‹èª¿æ•´æ–¹æ³•æ¬Šé‡ï¼Œå¯ä»¥åœ¨ä¿æŒå™ªéŸ³ç©©å¥æ€§çš„åŒæ™‚é™ä½å»¶é²

### Strategy
```python
SNR > 30dB (Clean):  mfcc_dtw=0.7, mel=0.2, lpc=0.1  # Fast
15-30dB (Moderate):  mfcc_dtw=0.4, mel=0.4, lpc=0.2  # Balanced
SNR < 15dB (Noisy):  mfcc_dtw=0.2, mel=0.7, lpc=0.1  # Stable (mel æŠ—å™ª)
```

### Success Metrics
| Metric | Baseline | Target | Stretch |
|--------|----------|--------|---------|
| 10dB Accuracy | 71% | **75%** | 78% |
| Clean Latency | 220ms | **180ms** | 170ms |
| Overall Accuracy | 94.6% | **95%** | 96% |

### Implementation Steps
1. âœ… **Plan** - Done
2. â³ Create `src/audio_utils.py` - SNR estimation (10 min)
3. â³ Add `get_adaptive_weights()` to `recognizers.py` (5 min)
4. â³ Modify `MultiMethodMatcher.recognize()` (10 min)
5. â³ Update `test_arena.py` - add `adaptive_ensemble` (5 min)
6. â³ Run baseline test (5 min)
7. â³ Run adaptive test (5 min)
8. â³ Analyze & document (10 min)

### Files to Create/Modify
- **New**: `src/audio_utils.py`
- **Modify**: `src/recognizers.py`, `test_arena.py`
- **Output**: `record/arena_adaptive_ensemble_*.json`

### Next Steps if Success
- Fine-tune weight thresholds
- Try aggressive strategy (skip methods in clean env)
- Move to A2 (Spectral Subtraction)

### Next Steps if Failure
- Analyze SNR estimation accuracy
- Adjust weight allocation
- **Pivot**: Move to A2 (preprocessing approach)

---

## A2: Spectral Subtraction

### Overview
**Type**: Advanced Feature (Preprocessing)
**Difficulty**: â­â­â­â˜†â˜† (Medium)
**Time**: ~2-3 hours
**Risk**: Medium (å¯èƒ½å¼•å…¥å¤±çœŸ)

### Problem
- å™ªéŸ³ç›´æ¥æ±¡æŸ“éŸ³è¨Šä¿¡è™Ÿ
- ç„¡è«–ç”¨ä»€éº¼ç‰¹å¾µï¼Œå™ªéŸ³éƒ½æœƒå½±éŸ¿è¾¨è­˜
- éœ€è¦åœ¨ç‰¹å¾µæå–å‰å…ˆç§»é™¤å™ªéŸ³

### Hypothesis
> åœ¨ç‰¹å¾µæå–å‰ä¼°è¨ˆä¸¦æ¸›å»å™ªéŸ³é »è­œï¼Œå¯é¡¯è‘—æå‡ 10dB æº–ç¢ºç‡

### Strategy

**Spectral Subtraction åŸç†**:
1. ä¼°è¨ˆå™ªéŸ³åŠŸç‡è­œï¼ˆå¾éœéŸ³æ®µï¼‰
2. å¾æ•´é«”ä¿¡è™ŸåŠŸç‡è­œæ¸›å»å™ªéŸ³åŠŸç‡è­œ
3. é‡å»ºä¹¾æ·¨çš„éŸ³è¨Šä¿¡è™Ÿ

```python
def spectral_subtraction(noisy_audio, sr=16000, alpha=2.0):
    """
    é »è­œæ¸›æ³•å™ªéŸ³æ¶ˆé™¤

    Args:
        noisy_audio: å«å™ªéŸ³çš„éŸ³è¨Š
        alpha: éæ¸›å› å­ (over-subtraction factor)

    Returns:
        Enhanced audio
    """
    # 1. STFT
    D = librosa.stft(noisy_audio)
    magnitude = np.abs(D)
    phase = np.angle(D)

    # 2. ä¼°è¨ˆå™ªéŸ³è­œ (å‡è¨­å‰ 5 å¹€æ˜¯ç´”å™ªéŸ³)
    noise_magnitude = np.mean(magnitude[:, :5], axis=1, keepdims=True)

    # 3. é »è­œæ¸›æ³•
    enhanced_magnitude = magnitude - alpha * noise_magnitude
    enhanced_magnitude = np.maximum(enhanced_magnitude, 0.1 * magnitude)  # Floor

    # 4. ISTFT é‡å»º
    enhanced_D = enhanced_magnitude * np.exp(1j * phase)
    enhanced_audio = librosa.istft(enhanced_D)

    return enhanced_audio
```

### Success Metrics
| Metric | Baseline | Target | Stretch |
|--------|----------|--------|---------|
| **10dB Accuracy** | 71% | **80%** | 85% |
| 15dB Accuracy | 79% | **85%** | 90% |
| Clean Accuracy | 100% | **100%** | 100% (ä¸èƒ½é€€åŒ–) |
| Latency Overhead | - | **<20ms** | <10ms |

### Implementation Steps
1. â³ Research librosa spectral enhancement methods (30 min)
2. â³ Implement `spectral_subtraction()` in `audio_utils.py` (45 min)
3. â³ Add preprocessing option to recognizers (15 min)
4. â³ Test on Arena with/without preprocessing (20 min)
5. â³ Fine-tune alpha parameter (30 min)
6. â³ Document results (20 min)

### Hyperparameters to Tune
```python
ALPHA = [1.5, 2.0, 2.5, 3.0]  # Over-subtraction factor
NOISE_FRAMES = [3, 5, 10]     # å‡è¨­å‰ N å¹€æ˜¯å™ªéŸ³
FLOOR_RATIO = [0.1, 0.2]      # é¿å…éåº¦æ¸›æ³•
```

### Risks & Mitigations
- âš ï¸ **Risk**: å¯èƒ½å¼•å…¥ musical noiseï¼ˆé »è­œå¤±çœŸï¼‰
  - **Mitigation**: ä½¿ç”¨ floor é™åˆ¶ï¼Œé¿å…éåº¦æ¸›æ³•
- âš ï¸ **Risk**: å‡è¨­å‰å¹¾å¹€æ˜¯ç´”å™ªéŸ³å¯èƒ½ä¸æˆç«‹
  - **Mitigation**: ä½¿ç”¨ VAD æ‰¾çœŸæ­£çš„éœéŸ³æ®µ

### Files to Create/Modify
- **Modify**: `src/audio_utils.py` - add spectral_subtraction
- **Modify**: `src/recognizers.py` - add preprocessing option
- **Modify**: `test_arena.py` - add `--preprocess spectral_sub`
- **Output**: `record/arena_spectral_sub_*.json`

### Next Steps if Success
- Combine with A1 (adaptive + preprocessing)
- Try other preprocessing: Wiener filtering
- Move to A3 (new features)

### Next Steps if Failure
- Try simpler preprocessing (bandpass filter)
- **Pivot**: Focus on template quality improvement

---

## A3: RASTA-PLP Features

### Overview
**Type**: Advanced Feature (New Feature Extractor)
**Difficulty**: â­â­â­â­â˜† (High)
**Time**: ~4-6 hours
**Risk**: High (å¤§å¹…æ”¹å‹•)

### Problem
- MFCC åœ¨å™ªéŸ³ä¸‹æ€§èƒ½ä¸‹é™
- éœ€è¦æ›´æŠ—å™ªçš„ç‰¹å¾µè¡¨ç¤º
- RASTA-PLP å°ˆç‚ºå™ªéŸ³ç©©å¥æ€§è¨­è¨ˆ

### Hypothesis
> RASTA-PLP ç‰¹å¾µæ¯” MFCC æ›´æŠ—å™ªéŸ³ï¼Œå¯æå‡ 10dB æº–ç¢ºç‡

### Background

**RASTA-PLP vs MFCC**:
| Feature | MFCC | RASTA-PLP |
|---------|------|-----------|
| é »ç‡å°ºåº¦ | Mel | Bark (æ›´ç¬¦åˆè½è¦º) |
| å™ªéŸ³è™•ç† | ç„¡ | RASTA æ¿¾æ³¢å™¨ï¼ˆç§»é™¤æ…¢è®Šå™ªéŸ³ï¼‰ |
| é€šé“æ•ˆæ‡‰ | æ•æ„Ÿ | æŠ—é€šé“è®ŠåŒ– |
| è¨ˆç®—è¤‡é›œåº¦ | ä½ | ä¸­ |

**RASTA Filter**:
- é«˜é€šæ¿¾æ³¢å™¨ï¼Œç§»é™¤é »è­œåŒ…çµ¡çš„æ…¢é€Ÿè®ŠåŒ–
- ä¿ç•™å¿«é€Ÿè®ŠåŒ–ï¼ˆèªéŸ³ç‰¹æ€§ï¼‰
- å»é™¤ç©©æ…‹å™ªéŸ³

### Strategy

```python
# Using python_speech_features or custom implementation
from python_speech_features import rasta_plp

def extract_rasta_plp(audio, sr=16000, n_coeffs=13):
    """
    æå– RASTA-PLP ç‰¹å¾µ

    Returns:
        RASTA-PLP coefficients (shape: [n_frames, n_coeffs])
    """
    features = rasta_plp(audio, samplerate=sr, numcep=n_coeffs)
    return features
```

### Success Metrics
| Metric | MFCC | RASTA-PLP Target | Improvement |
|--------|------|------------------|-------------|
| **10dB Accuracy** | 64% | **75%+** | +11% |
| 15dB Accuracy | 79% | **85%+** | +6% |
| Clean Accuracy | 100% | **98%+** | -2% (å¯æ¥å—) |

### Implementation Steps
1. â³ Research RASTA-PLP libraries (1 hour)
2. â³ Install dependencies (python_speech_features) (15 min)
3. â³ Create `RastaPLPMatcher` class (1 hour)
4. â³ Test on single template (30 min)
5. â³ Run Arena test (10 min)
6. â³ Compare with MFCC (30 min)
7. â³ Add to ensemble if successful (30 min)
8. â³ Document results (30 min)

### Files to Create/Modify
- **New**: `src/features.py` - RASTA-PLP extraction
- **New**: Class in `recognizers.py` - RastaPLPMatcher
- **Modify**: `MultiMethodMatcher` - add rasta_plp option
- **Output**: `record/arena_rasta_plp_*.json`

### Risks & Mitigations
- âš ï¸ **Risk**: RASTA-PLP å¯èƒ½åœ¨å®‰éœç’°å¢ƒè¡¨ç¾è¼ƒå·®
  - **Mitigation**: åªåœ¨å™ªéŸ³ç’°å¢ƒå•Ÿç”¨ï¼Œæˆ–åŠ å…¥ ensemble
- âš ï¸ **Risk**: å¯¦æ–½è¤‡é›œï¼Œå¯èƒ½å¼•å…¥ bugs
  - **Mitigation**: å¾ç°¡å–®å¯¦ç¾é–‹å§‹ï¼Œé€æ­¥å„ªåŒ–
- âš ï¸ **Risk**: è¨ˆç®—é–‹éŠ·å¢åŠ 
  - **Mitigation**: Profile æ€§èƒ½ï¼Œå¿…è¦æ™‚å„ªåŒ–

### Next Steps if Success
- Add RASTA-PLP to adaptive ensemble
- Test combined effect (A1 + A2 + A3)
- **Goal**: 10dB accuracy >85%

### Next Steps if Failure
- RASTA-PLP å¯èƒ½ä¸é©åˆæ­¤æ‡‰ç”¨
- **Pivot**: å›åˆ°æ¨¡æ¿è³ªé‡æ”¹å–„

---

## B1: Arena æ¥µç«¯æ¢ä»¶æ¸¬è©¦

### Overview
**Type**: Testing Enhancement
**Difficulty**: â­â˜†â˜†â˜†â˜† (Very Low)
**Time**: ~1 hour (implementation) + 10 min per test
**Risk**: None (ç´”æ¸¬è©¦)

### Problem
- ç•¶å‰ Arena æ¸¬è©¦å¯èƒ½ä¸å¤ åš´æ ¼
- ä¸çŸ¥é“ç³»çµ±çš„çœŸæ­£æ¥µé™åœ¨å“ªè£¡
- éœ€è¦æ›´æ¥µç«¯çš„æ¢ä»¶ä¾†æš´éœ²å¼±é»

### Hypothesis
> æ›´æ¥µç«¯çš„æ¸¬è©¦æ¢ä»¶æœƒæš´éœ²ç•¶å‰ç³»çµ±çš„æ¥µé™ï¼Œå¹«åŠ©æ‰¾åˆ°ä¸‹ä¸€æ­¥å„ªåŒ–æ–¹å‘

### New Test Suites

```python
# Current (Baseline)
TEST_SUITES = {
    'Speed': [0.7, 0.9, 1.0, 1.1, 1.3],
    'Pitch': [-2.5, -1.0, 0.0, 1.0, 2.5],
    'Noise': [100, 25, 20, 15, 10],
    'Volume': [0.3, 0.6, 1.0, 1.5, 3.0]
}

# New (Extreme)
TEST_SUITES_EXTREME = {
    'Speed': [0.5, 0.7, 0.9, 1.0, 1.1, 1.3, 1.5],  # +2 extreme values
    'Pitch': [-5, -2.5, 0.0, 2.5, 5],              # Doubled range
    'Noise': [100, 25, 20, 15, 10, 5, 0],          # +2 extreme (5dB, 0dB)
    'Volume': [0.1, 0.3, 0.6, 1.0, 1.5, 3.0, 5.0]  # +2 extreme
}
```

### Test Matrix Comparison

| Suite | Current Conditions | Extreme Conditions | Added |
|-------|-------------------|-------------------|--------|
| Speed | 5 | **7** | +40% |
| Pitch | 5 | **5** | (doubled range) |
| Noise | 5 | **7** | +40% |
| Volume | 5 | **7** | +40% |
| **Total** | **20** | **26** | **+30% scenarios** |

### Success Metrics
**Goal**: æ‰¾å‡ºç³»çµ±å´©æ½°é»

| Condition | Expected Accuracy | Failure Threshold |
|-----------|-------------------|-------------------|
| Speed 0.5x | 70-80% | <60% = serious issue |
| Speed 1.5x | 70-80% | <60% |
| Pitch Â±5st | 60-70% | <50% |
| Noise 5dB | 40-50% | <30% = unusable |
| Noise 0dB | 20-30% | Expected to fail |
| Volume 0.1x | 50-60% | <40% |
| Volume 5.0x | 80-90% | <70% |

### Implementation Steps
1. â³ Create `test_arena_extreme.py` (copy from test_arena.py) (10 min)
2. â³ Update TEST_SUITES to extreme values (5 min)
3. â³ Run extreme test (10 min)
4. â³ Compare with baseline (10 min)
5. â³ Document failure modes (30 min)

### Analysis Questions
1. **At what noise level does the system become unusable?** (Target: >5dB)
2. **How extreme speed variation can it handle?** (Target: 0.5x-1.5x)
3. **Which condition degrades fastest?** (Likely: extreme noise)
4. **Are there catastrophic failure modes?** (e.g., all commands â†’ NOISE)

### Files to Create
- **New**: `test_arena_extreme.py`
- **Output**: `record/arena_extreme_*.json`
- **Report**: `record/test_extreme_conditions_report.md`

### Next Steps
- Identify worst-performing conditions
- Prioritize optimization efforts
- Use as benchmark for future improvements

---

## B2: Arena æ··åˆæ¢ä»¶æ¸¬è©¦

### Overview
**Type**: Testing Enhancement
**Difficulty**: â­â­â˜†â˜†â˜† (Low-Medium)
**Time**: ~2 hours (implementation) + 15 min per test
**Risk**: None (ç´”æ¸¬è©¦)

### Problem
- ç•¶å‰æ¸¬è©¦åªæœ‰å–®ä¸€æ¢ä»¶è®ŠåŒ–
- çœŸå¯¦ç’°å¢ƒå¸¸æ˜¯å¤šç¨®å¹²æ“¾åŒæ™‚å­˜åœ¨
- ä¾‹å¦‚ï¼šå¿«é€Ÿèªªè©± + èƒŒæ™¯å™ªéŸ³ + è·é›¢é ï¼ˆéŸ³é‡å°ï¼‰

### Hypothesis
> æ··åˆæ¢ä»¶æœƒæš´éœ²å–®ä¸€æ¢ä»¶æ¸¬è©¦ç„¡æ³•ç™¼ç¾çš„å¼±é»

### Test Scenarios

**Scenario Design**:
```python
MIXED_SCENARIOS = {
    # Realistic scenarios
    'indoor_quiet': {
        'speed': 1.0,
        'pitch': 0.0,
        'noise_snr': 100,
        'volume': 1.0
    },
    'fast_speech_noisy': {  # å¿«é€Ÿèªªè©± + å™ªéŸ³
        'speed': 1.3,
        'pitch': 0.0,
        'noise_snr': 15,
        'volume': 1.0
    },
    'distant_speaker': {  # è·é›¢é  + è¼•å¾®å™ªéŸ³
        'speed': 1.0,
        'pitch': 0.0,
        'noise_snr': 25,
        'volume': 0.3
    },
    'excited_speaker': {  # æ¿€å‹•èªªè©±ï¼ˆå¿«é€Ÿ + éŸ³é«˜é«˜ + å¤§è²ï¼‰
        'speed': 1.2,
        'pitch': 2.0,
        'noise_snr': 100,
        'volume': 2.0
    },
    'tired_speaker': {  # ç–²å€¦èªªè©±ï¼ˆæ…¢é€Ÿ + éŸ³é«˜ä½ + å°è²ï¼‰
        'speed': 0.8,
        'pitch': -2.0,
        'noise_snr': 100,
        'volume': 0.5
    },
    'outdoor_demo': {  # æˆ¶å¤–å±•ç¤ºï¼ˆå™ªéŸ³ + è·é›¢ + å¯èƒ½éŸ³é«˜è®ŠåŒ–ï¼‰
        'speed': 1.0,
        'pitch': 1.0,
        'noise_snr': 10,
        'volume': 0.5
    },
    'factory_environment': {  # å·¥å» ç’°å¢ƒï¼ˆåš´é‡å™ªéŸ³ï¼‰
        'speed': 1.0,
        'pitch': 0.0,
        'noise_snr': 5,
        'volume': 2.0  # éœ€è¦å¤§è²èªª
    },
    'worst_case': {  # æœ€å£æƒ…æ³
        'speed': 1.3,
        'pitch': 2.5,
        'noise_snr': 10,
        'volume': 0.3
    }
}
```

### Expected Results

| Scenario | Expected Acc | Why |
|----------|-------------|-----|
| indoor_quiet | 100% | Baseline (clean) |
| fast_speech_noisy | 60-70% | Speed OK, but 15dB noise hurts |
| distant_speaker | 70-80% | Volume shouldn't matter much |
| excited_speaker | 90-95% | All factors within tolerance |
| tired_speaker | 85-90% | Slow is fine, low pitch OK |
| outdoor_demo | 50-60% | 10dB noise + volume = challenging |
| factory_environment | 40-50% | 5dB noise is very hard |
| worst_case | 30-40% | Everything wrong at once |

### Implementation Steps
1. â³ Design mixed scenarios (30 min)
2. â³ Modify `apply_augmentation()` to support multiple effects (30 min)
3. â³ Create `test_arena_mixed.py` (45 min)
4. â³ Run mixed tests (15 min)
5. â³ Analyze interaction effects (30 min)
6. â³ Document findings (30 min)

### Analysis Questions
1. **Do effects compound or cancel?**
   - E.g., speed + noise worse than sum of individual effects?
2. **Which combinations are worst?**
   - Likely: noise + speed or noise + volume
3. **Can we identify "safe zones"?**
   - E.g., "OK if SNR >15dB regardless of speed"

### Files to Create
- **New**: `test_arena_mixed.py`
- **Modify**: `apply_augmentation()` - support multi-effect
- **Output**: `record/arena_mixed_*.json`
- **Report**: `record/test_mixed_conditions_report.md`

### Next Steps
- Use findings to prioritize real-world optimization
- Create deployment guidelines (e.g., "works best in quiet <15dB")

---

## C1: MFCC åƒæ•¸ç¶²æ ¼æœç´¢

### Overview
**Type**: Hyperparameter Tuning
**Difficulty**: â­â­â˜†â˜†â˜† (Low-Medium)
**Time**: ~6-8 hours (mostly waiting)
**Risk**: Low

### Problem
- ç•¶å‰ MFCC åƒæ•¸å¯èƒ½ä¸æ˜¯æœ€å„ª
- ä½¿ç”¨é»˜èªå€¼ï¼šn_mfcc=13, n_fft=1024, hop_length=512
- ç³»çµ±åŒ–æœç´¢å¯èƒ½æ‰¾åˆ°æ›´å¥½çš„çµ„åˆ

### Hypothesis
> å„ªåŒ– MFCC åƒæ•¸å¯æå‡ 0.5-2% æº–ç¢ºç‡

### Search Space

```python
PARAM_GRID = {
    'n_mfcc': [10, 13, 16, 20],           # 4 values
    'n_fft': [512, 1024, 2048],           # 3 values
    'hop_length': [256, 512, 1024],       # 3 values
    'n_mels': [64, 128, 256],             # 3 values (for mel method)
    'fmin': [80, 100, 133],               # 3 values
    'fmax': [7600, 8000, 16000],          # 3 values
}

# Total combinations: 4 Ã— 3 Ã— 3 = 36 for MFCC alone
# With n_mels: 36 Ã— 3 = 108 total
```

### Search Strategy

**Option A: Full Grid Search** (not recommended)
- 108 configurations Ã— 5 min = **9 hours**
- Too slow

**Option B: Random Search** (recommended)
- Sample 20 random configurations
- 20 Ã— 5 min = **100 minutes**
- Statistically likely to find good configs

**Option C: Bayesian Optimization** (advanced)
- Use Optuna or similar
- Intelligent sampling based on previous results
- ~30 trials = **150 minutes**
- Higher chance of finding global optimum

### Implementation Steps

**Phase 1: Setup** (30 min)
1. â³ Create `scripts/grid_search_mfcc.py`
2. â³ Implement parameter sampling
3. â³ Setup logging for all trials

**Phase 2: Search** (2-3 hours)
4. â³ Run random search (20 configs)
5. â³ Monitor progress
6. â³ Save all results

**Phase 3: Analysis** (1 hour)
7. â³ Rank configurations by overall accuracy
8. â³ Analyze parameter importance
9. â³ Test top 3 configs on Arena
10. â³ Document findings

### Success Metrics

| Metric | Current | Target | Stretch |
|--------|---------|--------|---------|
| Overall Accuracy | 94.3% | **95%** | 96% |
| 10dB Accuracy | 64% | **68%** | 70% |
| Latency | 165ms | **<170ms** | <165ms (no degradation) |

### Files to Create
- **New**: `scripts/grid_search_mfcc.py`
- **Output**: `record/grid_search_results.json`
- **Report**: `record/grid_search_report.md`

### Expected Findings
- n_mfcc: Likely 13-16 is optimal (more may overfit)
- n_fft: 1024 likely already optimal
- hop_length: May find 256 gives better time resolution

### Next Steps if Success
- Update `config.py` with best parameters
- Validate on fresh test set
- Combine with other improvements

---

## C2: Threshold ç²¾èª¿

### Overview
**Type**: Hyperparameter Tuning
**Difficulty**: â­â­â˜†â˜†â˜† (Low-Medium)
**Time**: ~4-6 hours (mostly waiting)
**Risk**: Low

### Problem
- ç•¶å‰ thresholds åŸºæ–¼ç¶“é©—è¨­å®š
- THRESHOLD_MFCC_DTW = 140.0 (å·²é©—è­‰ï¼Œä½†å¯èƒ½ä¸æ˜¯å…¨å±€æœ€å„ª)
- THRESHOLD_MEL = 0.40
- THRESHOLD_LPC = 100.0

### Hypothesis
> ç³»çµ±åŒ–æœç´¢ threshold çµ„åˆå¯æ¸›å°‘ false positives/negatives

### Search Space

```python
THRESHOLD_GRID = {
    'mfcc_dtw': [120, 130, 140, 150, 160],  # 5 values
    'mel': [0.35, 0.40, 0.45, 0.50],        # 4 values
    'lpc': [80, 90, 100, 110, 120],         # 5 values
}

# Total combinations: 5 Ã— 4 Ã— 5 = 100
# At ~5 min each = 500 minutes = 8+ hours (too slow)
```

### Search Strategy

**Option A: Sequential Optimization** (recommended)
1. Fix mel, lpc â†’ optimize mfcc_dtw (5 trials)
2. Fix mfcc_dtw, lpc â†’ optimize mel (4 trials)
3. Fix mfcc_dtw, mel â†’ optimize lpc (5 trials)
4. **Total: 14 trials Ã— 5 min = 70 minutes**

**Option B: Random Search**
- Sample 25 random combinations
- **Total: 125 minutes**

**Option C: Focus on mfcc_dtw only**
- Already validated 140 is good
- Fine search around it: [135, 138, 140, 142, 145]
- **Total: 5 trials Ã— 5 min = 25 minutes**

### Metrics to Optimize

**Primary**: Overall Accuracy
**Secondary**: Balance between:
- False Positives (wrong command detected)
- False Negatives (NOISE when should be command)

**Ideal Threshold**:
```
Maximize: Correct commands
Minimize: Wrong commands + False alarms
```

### Implementation Steps

**Phase 1: Setup** (20 min)
1. â³ Create `scripts/threshold_search.py`
2. â³ Implement sequential optimization
3. â³ Add metrics tracking

**Phase 2: Search** (1-2 hours)
4. â³ Run sequential search
5. â³ Monitor FP/FN rates
6. â³ Save results

**Phase 3: Validation** (30 min)
7. â³ Test top 3 threshold sets on Arena
8. â³ Compare with baseline
9. â³ Document findings

### Success Metrics

| Metric | Current | Target |
|--------|---------|--------|
| Overall Accuracy | 94.6% | **95%+** |
| FP Rate (wrong cmd) | ~3% | **<2%** |
| FN Rate (missed cmd) | ~2% | **<1.5%** |

### Files to Create
- **New**: `scripts/threshold_search.py`
- **Output**: `record/threshold_search_results.json`
- **Report**: `record/threshold_optimization_report.md`

### Expected Findings
- mfcc_dtw threshold: Likely 140 is already near-optimal (previously validated)
- mel threshold: May benefit from slight adjustment
- lpc threshold: May need increase (currently many false positives)

### Next Steps if Success
- Update `config.py` with optimal thresholds
- Validate stability across different test sets
- Combine with other improvements

---

# ğŸ—ºï¸ Complete Roadmap Summary

## Recommended Execution Order

### Week 1: Quick Wins
```
Day 1: A1 - Noise-Adaptive Ensemble (50 min) â­ START HERE
Day 2: B1 - Extreme Testing (1 hour)
Day 3: C2 - Threshold Fine-tune (2 hours)
```
**Expected Gain**: +1-2% accuracy, -10% latency

### Week 2: Deep Optimization
```
Day 1-2: A2 - Spectral Subtraction (3 hours)
Day 3: B2 - Mixed Conditions (2 hours)
```
**Expected Gain**: +5-10% at 10dB noise

### Week 3: Advanced Features (if needed)
```
Day 1-3: A3 - RASTA-PLP (6 hours)
Day 4-5: C1 - MFCC Grid Search (4 hours)
```
**Expected Gain**: +2-3% overall accuracy

---

## Success Milestones

### Milestone 1: 95% Overall Accuracy âœ…
- **Path**: A1 + C2
- **Time**: 3 days
- **Probability**: High (80%)

### Milestone 2: 75% at 10dB Noise ğŸ¯
- **Path**: A1 + A2
- **Time**: 1 week
- **Probability**: Medium (60%)

### Milestone 3: 80% at 10dB Noise ğŸš€
- **Path**: A1 + A2 + A3
- **Time**: 2-3 weeks
- **Probability**: Medium-Low (40%)

### Milestone 4: Production Ready ğŸ†
- **Path**: All optimizations + comprehensive testing
- **Time**: 4 weeks
- **Criteria**:
  - Overall â‰¥96%
  - 10dB â‰¥75%
  - Latency <200ms
  - Robust in mixed conditions

---

## Dependency Graph

```
A1 (Adaptive Ensemble) â­ START
â”œâ”€â†’ A2 (Spectral Sub) [if A1 succeeds]
â”‚   â””â”€â†’ A3 (RASTA-PLP) [if A2 succeeds]
â”‚
â”œâ”€â†’ B1 (Extreme Test) [parallel, validation]
â”‚   â””â”€â†’ B2 (Mixed Test) [after B1]
â”‚
â””â”€â†’ C2 (Threshold) [quick win, parallel]
    â””â”€â†’ C1 (MFCC Grid) [if time permits]
```

---

## Resource Requirements

| Experiment | Time | Compute | Risk | Priority |
|------------|------|---------|------|----------|
| A1 | 50 min | Low | Low | â­â­â­â­â­ |
| A2 | 3 hours | Medium | Medium | â­â­â­â­â˜† |
| A3 | 6 hours | Medium | High | â­â­â­â˜†â˜† |
| B1 | 1 hour | Low | None | â­â­â­â­â˜† |
| B2 | 2 hours | Low | None | â­â­â­â˜†â˜† |
| C1 | 4 hours | High | Low | â­â­â˜†â˜†â˜† |
| C2 | 2 hours | Medium | Low | â­â­â­â­â˜† |

---

## ğŸ¯ Decision: What to Start?

**My Recommendation**: **A1 (Noise-Adaptive Ensemble)**

**Why?**
- âœ… Highest priority (â­â­â­â­â­)
- âœ… Lowest risk
- âœ… Fastest implementation (50 min)
- âœ… High success probability
- âœ… Good foundation for A2, A3

**Ready to proceed with A1?** ğŸš€

Or would you like to:
- Review any specific experiment plan in detail?
- Adjust the roadmap?
- Start with a different experiment?
