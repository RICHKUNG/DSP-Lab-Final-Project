# 準確率分析與改進建議

**日期:** 2025-12-09
**當前準確率:** 80.0% (Ensemble)
**目標:** 找出提升準確率的方法

---

## 📊 當前狀況

### 整體表現
| 方法 | 平均準確率 | 角色 |
|------|-----------|------|
| **MFCC-DTW** | **80.0%** | 主力方法 ✅ |
| Mel-Spectrogram | 44-53% | 輔助方法 ⚠️ |
| LPC (FastLPCMatcher) | 50.7% | 輔助方法 ⚠️ |
| **Ensemble** | **80.0%** | = MFCC ⚠️ |

### 關鍵發現
1. **Ensemble = MFCC**: 集成方法的準確率等於MFCC單一方法
2. **Mel/LPC未貢獻**: 輔助方法未能提升整體準確率
3. **準確率瓶頸**: 已達當前特徵/模板組合的上限

---

## 🔬 實驗歷程

### 實驗1: 調整閾值使其更嚴格
**假設:** Mel和LPC投票太隨意，需要更保守的閾值

**測試配置:**
- Mel: 0.45 → 0.35 (更嚴格22%)
- LPC: 80.0 → 120.0 (更嚴格50%)

**結果:**
| 配置 | Mel準確率 | LPC準確率 | Ensemble準確率 |
|------|----------|----------|---------------|
| 原始 (0.45/80) | 53.0% | 50.3% | 80.3% |
| 嚴格 (0.35/120) | 44.7% | 50.7% | 80.0% |

**結論:** ❌ 閾值調整無效
- Mel變得太保守，準確率下降
- Ensemble準確率未提升
- 說明問題不在閾值，而在特徵本身

---

## 💡 根本原因分析

### 為何Mel/LPC準確率低？

#### 1. Mel-Spectrogram (44-53%)
**弱點:**
- **音高變化敏感**: Pitch變化時準確率暴跌至0-20%
- **時間結構丟失**: 將頻譜resize到固定尺寸會失去時序資訊
- **區分度不足**: 不同指令的Mel特徵太相似

**為何在噪音中表現尚可？**
- Mel保留頻譜整體輪廓，噪音影響相對均勻
- 但這不足以彌補其他條件下的弱點

#### 2. LPC (FastLPCMatcher) (50.7%)
**弱點:**
- **噪音環境崩潰**: 噪音條件下只有40%準確率
- **固定尺寸問題**: Resize LPC特徵會失真
- **歐式距離限制**: 相比DTW缺少時序對齊能力

**為何改用FastLPCMatcher？**
- 原本LPC+DTW太慢 (480ms)
- 改用固定尺寸+歐式距離換取速度 (37ms)
- 但犧牲了準確率

#### 3. MFCC-DTW (80.0%)
**優勢:**
- **DTW對齊**: 能處理速度/音高變化
- **梅爾頻率**: 貼近人耳感知
- **三角濾波器組**: 提供良好的頻譜摘要
- **MFCC係數**: 去相關性，保留主要資訊

---

## 🚀 提升準確率的真正方法

### ⭐ 方法1: 改善模板品質（最有效）

#### 問題模板識別
根據Arena測試，以下模板失敗率最高：
- **開始.wav (跳.wav)**: 0%準確率（全部失敗）
- **暫停.wav**: 在速度/音高變化時易誤判

#### 具體行動
```bash
# 1. 重新錄製問題模板
- 確保發音清晰、音量適中
- 多錄製幾個版本，選擇最具代表性的
- 避免背景噪音

# 2. 增加模板數量
- 每個指令從5個增加到8-10個模板
- 涵蓋不同說話者、語速、音調

# 3. 平衡模板品質
- 確保每個指令的模板品質一致
- 移除品質差的模板
```

**預期效果:** 準確率 80% → 85-90%

---

### ⭐ 方法2: 改進特徵工程

#### Option A: 改良MFCC
```python
# 增加MFCC維度
N_MFCC = 13 → 20  # 更多頻譜資訊

# 加入動態特徵
- Delta-MFCC (一階導數)
- Delta-Delta-MFCC (二階導數)
```

#### Option B: 混合時頻特徵
```python
# 結合MFCC + 時域特徵
- Zero Crossing Rate (過零率)
- Short-time Energy (短時能量)
- Spectral Centroid (頻譜重心)
```

**預期效果:** 準確率 80% → 82-85%

---

### ⭐ 方法3: 模板特定優化

某些指令可能需要不同的識別策略。

#### 分析各指令表現
```python
# 建議創建此工具
python temp/analyze_per_command.py

# 輸出類似:
# PAUSE: 95% (Very good)
# JUMP:  85% (Good)
# START: 60% (Needs improvement)
```

#### 指令特定調整
```python
# 為表現差的指令使用更寬鬆的閾值
COMMAND_THRESHOLDS = {
    'START': 150.0,  # 更寬鬆
    'PAUSE': 130.0,  # 更嚴格
    'JUMP':  140.0,  # 標準
}
```

**預期效果:** 準確率 80% → 83-87%

---

### ⭐ 方法4: 深度學習方法（大工程）

如果需要更高準確率（>90%），考慮使用深度學習。

#### 選項
1. **CNN + LSTM**: 處理頻譜圖時序特徵
2. **Wav2Vec 2.0**: 預訓練語音模型
3. **Transformer**: 注意力機制處理語音

**優點:**
- 自動學習特徵表示
- 能達到95%+準確率

**缺點:**
- 需要大量訓練資料（數百到數千樣本）
- 推論延遲可能較高
- 模型複雜度增加

---

## 📋 推薦行動計畫

### 階段1: 快速改進（1-2小時）
1. ✅ **識別問題模板** - 使用Arena測試找出失敗模板
2. ⏳ **重新錄製開始.wav和跳.wav** - 確保清晰度
3. ⏳ **增加每個指令的模板數量** - 從5個增至7-8個
4. ⏳ **測試新模板** - 運行Arena測試驗證改進

**預期成果:** 80% → 85%

---

### 階段2: 特徵優化（2-4小時）
1. 增加MFCC維度到20
2. 加入動態特徵 (Delta, Delta-Delta)
3. 實現指令特定閾值
4. 測試並調整

**預期成果:** 85% → 87-90%

---

### 階段3: 深度學習（如需要，1-2週）
1. 收集更多訓練資料
2. 訓練CNN/LSTM或Transformer模型
3. 優化推論速度
4. 部署測試

**預期成果:** 90% → 95%+

---

## 🎯 當前建議配置

基於實驗結果，目前最佳配置：

```python
# src/config.py
DTW_RADIUS = 2              # 速度優化
THRESHOLD_MFCC_DTW = 140.0  # MFCC主力方法
THRESHOLD_MEL = 0.40        # Mel輔助（平衡）
THRESHOLD_LPC = 100.0       # LPC輔助（平衡）
```

**理由:**
- Mel 0.40比0.35更有用（不會太保守）
- LPC 100.0比120更有用（不會太嚴格）
- 雖然Mel/LPC個別準確率低，但偶爾能提供有用的輔助投票

---

## 📌 關鍵結論

1. **當前系統已優化至極限**: 在現有特徵和模板下，80%是天花板
2. **閾值調整無法突破**: 問題不在參數，而在特徵/模板品質
3. **優先改善模板**: 重新錄製問題樣本是最快的提升方法
4. **考慮新特徵**: MFCC已很好，但可加入更多輔助特徵
5. **Ensemble已最佳**: 當前就是讓MFCC主導，Mel/LPC輔助

---

## 📂 相關文件

- `temp/analyze_failures.py` - 分析失敗條件和方法
- `record/arena_*.json` - 歷史測試結果
- `exp_fast_1.md` - FastLPCMatcher優化記錄
- `exp_fast_2.md` - DTW radius優化記錄
- `OPTIMIZATION_SUMMARY.md` - 速度優化總結

---

**下一步建議:** 重新錄製開始.wav和跳.wav，增加每個指令的模板數量。
